{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Test Notebook to Draft Adversarial attack experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "# Load pretrained PyTorch feature extractor\n",
    "model = timm.create_model(\n",
    "    'resnet18.a1_in1k',\n",
    "    pretrained=True,\n",
    "    num_classes=0,  # remove classifier nn.Linear\n",
    ")\n",
    "feature_extractor = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load test data from pickle file\n",
    "#with open('W:/DS/Project/CNN Prototype/cifar-10-batches-py/test_batch', 'rb') as f:  # Replace with actual path\n",
    "with open('E:/Work/DS/Project/CNN Protoype/cifar-10-batches-py/test_batch', 'rb') as f:\n",
    "    data = pickle.load(f, encoding='bytes')\n",
    "\n",
    "BATCH_NUMBER = 10\n",
    "\n",
    "def load_batch(data, BATCH_NUMBER = BATCH_NUMBER, iteration = 0):\n",
    "    # Handle different data formats\n",
    "    if isinstance(data, dict):\n",
    "        x_test = data[b'data'][iteration*BATCH_NUMBER:(iteration + 1)*BATCH_NUMBER]\n",
    "        x_test = [Image.fromarray(image.reshape(3,32,32).transpose(1,2,0)) for image in x_test]\n",
    "        y_test = data[b'labels'][iteration*BATCH_NUMBER:(iteration + 1)*BATCH_NUMBER]\n",
    "    else:\n",
    "        x_test, y_test = data\n",
    "\n",
    "    y_test = pd.get_dummies(y_test).values\n",
    "\n",
    "    # Convert to PyTorch tensors for the feature extractor\n",
    "    x_test_pt = torch.stack([transforms(image) for image in x_test])  # NHWC to NCHW\n",
    "    y_test_pt = torch.tensor(y_test).float()\n",
    "    return x_test_pt, y_test_pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IFGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative FGSM (IFGSM) Attack Function\n",
    "def ifgsm_attack(input_image, label, epsilon, alpha = 1, iterations = 5, classifier = None):\n",
    "    adv_image = input_image.clone().detach()\n",
    "    for _ in range(iterations):\n",
    "        adv_image.requires_grad = True\n",
    "        features = feature_extractor(adv_image)\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            features_tf = tf.convert_to_tensor(features_np)\n",
    "            tape.watch(features_tf)\n",
    "            predictions = classifier(features_tf)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(label, predictions)\n",
    "\n",
    "        grad_features = tape.gradient(loss, features_tf).numpy()\n",
    "        grad_features_pt = torch.tensor(grad_features).to(adv_image.device)\n",
    "        features.backward(grad_features_pt)\n",
    "        grad_input = adv_image.grad.data\n",
    "\n",
    "        adv_image = adv_image + alpha * grad_input.sign()\n",
    "        perturbation = torch.clamp(adv_image - input_image, min=-epsilon, max=epsilon)\n",
    "        adv_image = (input_image + perturbation).detach()\n",
    "\n",
    "    return adv_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IFGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifgm_attack(input_image, label, epsilon, alpha = 1, iterations = 5, decay_factor=1.0, classifier = None):\n",
    "    adv_image = input_image.clone().detach()\n",
    "    momentum = torch.zeros_like(adv_image)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        adv_image.requires_grad = True\n",
    "        features = feature_extractor(adv_image)\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            features_tf = tf.convert_to_tensor(features_np)\n",
    "            tape.watch(features_tf)\n",
    "            predictions = classifier(features_tf)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(label, predictions)\n",
    "\n",
    "        grad_features = tape.gradient(loss, features_tf).numpy()\n",
    "        grad_features_pt = torch.tensor(grad_features).to(adv_image.device)\n",
    "        features.backward(grad_features_pt)\n",
    "        grad_input = adv_image.grad.data\n",
    "\n",
    "        momentum = decay_factor * momentum + grad_input / torch.norm(grad_input, p=1)\n",
    "        adv_image = adv_image + alpha * momentum\n",
    "        perturbation = torch.clamp(adv_image - input_image, min=-epsilon, max=epsilon)\n",
    "        adv_image = (input_image + perturbation).detach()\n",
    "\n",
    "    return adv_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L-BFGS Attack Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbfgs_attack(input_image, label, classifier = None):\n",
    "    def loss_fn(perturbation):\n",
    "        pert_image = input_image + torch.tensor(perturbation, dtype=torch.float32).reshape_as(input_image)\n",
    "        features = feature_extractor(pert_image)\n",
    "        predictions = classifier(features.detach().cpu().numpy())\n",
    "        loss = tf.keras.losses.categorical_crossentropy(label, predictions)\n",
    "        return loss.numpy().astype(np.float64)\n",
    "\n",
    "    perturbation = np.zeros_like(input_image.cpu().numpy())\n",
    "    result = minimize(loss_fn, perturbation, method='L-BFGS-B')\n",
    "    adversarial_image = input_image + torch.tensor(result.x, dtype=torch.float32).reshape_as(input_image)\n",
    "\n",
    "    return adversarial_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepFool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepfool_attack(input_image, label, max_iter=5, classifier = None):\n",
    "    adv_image = input_image.clone().detach()\n",
    "    for _ in range(max_iter):\n",
    "        adv_image.requires_grad = True\n",
    "        features = feature_extractor(adv_image)\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "        predictions = classifier(features_np)\n",
    "\n",
    "        if np.argmax(predictions) != np.argmax(label):\n",
    "            break\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            features_tf = tf.convert_to_tensor(features_np)\n",
    "            tape.watch(features_tf)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(label, predictions)\n",
    "\n",
    "        grad_features = tape.gradient(loss, features_tf).numpy()\n",
    "        grad_features_pt = torch.tensor(grad_features).to(adv_image.device)\n",
    "        features.backward(grad_features_pt)\n",
    "        grad_input = adv_image.grad.data\n",
    "\n",
    "        perturbation = grad_input / torch.norm(grad_input)\n",
    "        adv_image = adv_image + perturbation.sign() * 0.01  # small step size\n",
    "\n",
    "    return adv_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate on Adversarial Examples\n",
    "def evaluate_adversarial(epsilon=0.01, classifiers = None, num_samples=BATCH_NUMBER, classifiers_names = None, attacks_names = None):\n",
    "    correct = np.zeros(len(classifiers_names))\n",
    "    adv_correct = np.zeros((len(attacks_names),len(classifiers_names)))\n",
    "    for i in range(1):\n",
    "        x_test_pt, y_test_pt = load_batch(data, BATCH_NUMBER = BATCH_NUMBER, iteration = i)\n",
    "        for j in range(num_samples):\n",
    "            image = x_test_pt[j:j+1]\n",
    "            label = y_test_pt[j:j+1]\n",
    "            # Forward pass through both models\n",
    "            features = feature_extractor(image).detach().cpu().numpy()\n",
    "            for k,classifier in enumerate(classifiers):\n",
    "                pred = classifier.predict(features)\n",
    "                if np.argmax(pred) == np.argmax(label):\n",
    "                    correct[k] += 1\n",
    "                for n, attack_name in enumerate(attacks_names):\n",
    "                    if (attack_name == 'FGM'):\n",
    "                        adv_image = ifgm_attack(image.clone(), label, epsilon, iterations = 1, decay_factor=1.0, classifier = classifier)\n",
    "                    elif  (attack_name == 'IFGM'):\n",
    "                        adv_image = ifgm_attack(image.clone(), label, epsilon, iterations = 5, decay_factor=1.0, classifier = classifier)\n",
    "                    elif  (attack_name == 'FGSM'):\n",
    "                        adv_image = ifgsm_attack(image.clone(), label, epsilon, iterations = 1, decay_factor=1.0, classifier = classifier)\n",
    "                    elif  (attack_name == 'IFGSM'):\n",
    "                        adv_image = ifgsm_attack(image.clone(), label, epsilon, iterations = 5, decay_factor=1.0, classifier = classifier)\n",
    "                    elif  (attack_name == 'L-BFGS'):\n",
    "                        adv_image = lbfgs_attack(image.clone(), label, classifier = classifier)\n",
    "                    elif  (attack_name == 'deepfool'):\n",
    "                        adv_image = deepfool_attack(image.clone(), label, max_iter=5, classifier = classifier)\n",
    "\n",
    "\n",
    "                    adv_features = feature_extractor(adv_image).detach().cpu().numpy()\n",
    "                    adv_pred = classifier.predict(adv_features)\n",
    "                    if np.argmax(adv_pred) == np.argmax(label):\n",
    "                        adv_correct[n,k] += 1\n",
    "    accuracy = correct / 10\n",
    "    adv_accuracy = adv_correct / 10\n",
    "    for k,classifier in enumerate(classifiers):\n",
    "        print('Baseline Accuracy for ' + classifiers_names[k] + f' (ε = {epsilon}): {accuracy[k] * 100:.2f}%')\n",
    "        for n, attacks_name in enumerate(attacks_names):\n",
    "            print('Adversarial Accuracy for ' + classifiers_names[k] + 'on' + attacks_name + f' (ε = {epsilon}): {adv_accuracy[n,k] * 100:.2f}%')\n",
    "    return accuracy, adv_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_RBF_neuron import RBFLayer\n",
    "from custom_ENN_layerV2 import ENNLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class 'keras.src.models.functional.Functional'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras.src.models.functional', 'class_name': 'Functional', 'config': {'name': 'functional', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': [None, 512], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer'}, 'registered_name': None, 'name': 'input_layer', 'inbound_nodes': []}, {'module': 'custom_RBF_neuron', 'class_name': 'RBFLayer', 'config': {'name': 'rbf_layer', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 100, 'gamma': {'class_name': '__tensor__', 'config': {'value': 602.0853881835938, 'dtype': 'float32'}}}, 'registered_name': 'RBFLayer', 'build_config': {'input_shape': [None, 512]}, 'name': 'rbf_layer', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 512], 'dtype': 'float32', 'keras_history': ['input_layer', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 2681578012624}, 'units': 10, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 100]}, 'name': 'dense', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 100], 'dtype': 'float32', 'keras_history': ['rbf_layer', 0, 0]}}], 'kwargs': {}}]}], 'input_layers': [['input_layer', 0, 0]], 'output_layers': [['dense', 0, 0]]}, 'registered_name': 'Functional', 'build_config': {'input_shape': None}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'adam', 'learning_rate': 0.00019999999494757503, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': {'module': 'keras.losses', 'class_name': 'CategoricalCrossentropy', 'config': {'name': 'categorical_crossentropy', 'reduction': 'sum_over_batch_size', 'from_logits': False, 'label_smoothing': 0.0, 'axis': -1}, 'registered_name': None}, 'loss_weights': None, 'metrics': [{'module': 'keras.metrics', 'class_name': 'CategoricalAccuracy', 'config': {'name': 'categorical_accuracy', 'dtype': 'float32'}, 'registered_name': None}, {'module': 'keras.metrics', 'class_name': 'Precision', 'config': {'name': 'precision', 'dtype': 'float32', 'thresholds': None, 'top_k': None, 'class_id': None}, 'registered_name': None}, {'module': 'keras.metrics', 'class_name': 'Recall', 'config': {'name': 'recall', 'dtype': 'float32', 'thresholds': None, 'top_k': None, 'class_id': None}, 'registered_name': None}, {'module': 'keras.metrics', 'class_name': 'F1Score', 'config': {'name': 'f1_score', 'dtype': 'float32', 'average': 'micro', 'threshold': None}, 'registered_name': None}], 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': False}}.\n\nException encountered: <class 'custom_RBF_neuron.RBFLayer'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'custom_RBF_neuron', 'class_name': 'RBFLayer', 'config': {'name': 'rbf_layer', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 100, 'gamma': {'class_name': '__tensor__', 'config': {'value': 602.0853881835938, 'dtype': 'float32'}}}, 'registered_name': 'RBFLayer', 'build_config': {'input_shape': [None, 512]}, 'name': 'rbf_layer', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 512], 'dtype': 'float32', 'keras_history': ['input_layer', 0, 0]}}], 'kwargs': {}}]}.\n\nException encountered: Error when deserializing class 'RBFLayer' using config={'name': 'rbf_layer', 'trainable': True, 'dtype': 'float32', 'units': 100, 'gamma': {'class_name': '__tensor__', 'config': {'value': 602.0853881835938, 'dtype': 'float32'}}}.\n\nException encountered: Unrecognized keyword arguments passed to RBFLayer: {'gamma': {'class_name': '__tensor__', 'config': {'value': 602.0853881835938, 'dtype': 'float32'}}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py:234\u001b[0m, in \u001b[0;36mOperation.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32me:\\Work\\DS\\Project\\CNN Experiment\\custom_RBF_neuron.py:5\u001b[0m, in \u001b[0;36mRBFLayer.__init__\u001b[1;34m(self, units, **kwargs)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, units, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28msuper\u001b[39m(RBFLayer, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m units\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:266\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    269\u001b[0m     )\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Will be determined in `build_wrapper`\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized keyword arguments passed to RBFLayer: {'gamma': {'class_name': '__tensor__', 'config': {'value': 602.0853881835938, 'dtype': 'float32'}}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:718\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 718\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(inner_config)\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py:236\u001b[0m, in \u001b[0;36mOperation.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when deserializing class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Error when deserializing class 'RBFLayer' using config={'name': 'rbf_layer', 'trainable': True, 'dtype': 'float32', 'units': 100, 'gamma': {'class_name': '__tensor__', 'config': {'value': 602.0853881835938, 'dtype': 'float32'}}}.\n\nException encountered: Unrecognized keyword arguments passed to RBFLayer: {'gamma': {'class_name': '__tensor__', 'config': {'value': 602.0853881835938, 'dtype': 'float32'}}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:718\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 718\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(inner_config)\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\model.py:521\u001b[0m, in \u001b[0;36mModel.from_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional_from_config\n\u001b[1;32m--> 521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m functional_from_config(\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;28mcls\u001b[39m, config, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[0;32m    523\u001b[0m     )\n\u001b[0;32m    525\u001b[0m \u001b[38;5;66;03m# Either the model has a custom __init__, or the config\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;66;03m# does not contain all the information necessary to\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m# revive a Functional model. This happens when the user creates\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;66;03m# In this case, we fall back to provide all config into the\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;66;03m# constructor of the class.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py:477\u001b[0m, in \u001b[0;36mfunctional_from_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_data \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 477\u001b[0m     process_layer(layer_data)\n\u001b[0;32m    479\u001b[0m \u001b[38;5;66;03m# Then we process nodes in order of layer depth.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001b[39;00m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# is repeated until all nodes are processed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py:461\u001b[0m, in \u001b[0;36mfunctional_from_config.<locals>.process_layer\u001b[1;34m(layer_data)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m     layer \u001b[38;5;241m=\u001b[39m serialization_lib\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[0;32m    462\u001b[0m         layer_data, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[0;32m    463\u001b[0m     )\n\u001b[0;32m    464\u001b[0m created_layers[layer_name] \u001b[38;5;241m=\u001b[39m layer\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:720\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    721\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m could not be deserialized properly. Please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ensure that components that are Python object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    723\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m instances (layers, models, etc.) returned by\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    724\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `get_config()` are explicitly deserialized in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    725\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms `from_config()` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    726\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    727\u001b[0m     )\n\u001b[0;32m    728\u001b[0m build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: <class 'custom_RBF_neuron.RBFLayer'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'custom_RBF_neuron', 'class_name': 'RBFLayer', 'config': {'name': 'rbf_layer', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 100, 'gamma': {'class_name': '__tensor__', 'config': {'value': 602.0853881835938, 'dtype': 'float32'}}}, 'registered_name': 'RBFLayer', 'build_config': {'input_shape': [None, 512]}, 'name': 'rbf_layer', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 512], 'dtype': 'float32', 'keras_history': ['input_layer', 0, 0]}}], 'kwargs': {}}]}.\n\nException encountered: Error when deserializing class 'RBFLayer' using config={'name': 'rbf_layer', 'trainable': True, 'dtype': 'float32', 'units': 100, 'gamma': {'class_name': '__tensor__', 'config': {'value': 602.0853881835938, 'dtype': 'float32'}}}.\n\nException encountered: Unrecognized keyword arguments passed to RBFLayer: {'gamma': {'class_name': '__tensor__', 'config': {'value': 602.0853881835938, 'dtype': 'float32'}}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m neurons \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMP\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRBF\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mECF\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m MP_classifier \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/Work/DS/Project/CNN Experiment/ResNet18/CIFAR10/CIFAR10_ResNet18_MP_epochs_20.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Replace with actual path\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m RBF_classifier \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/Work/DS/Project/CNN Experiment/ResNet18/CIFAR10/CIFAR10_ResNet18_RBF_epochs_20.keras\u001b[39m\u001b[38;5;124m'\u001b[39m, custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRBFLayer\u001b[39m\u001b[38;5;124m'\u001b[39m: RBFLayer})  \u001b[38;5;66;03m# Replace with actual path\u001b[39;00m\n\u001b[0;32m      5\u001b[0m ECF_classifier \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/Work/DS/Project/CNN Experiment/ResNet18/CIFAR10/CIFAR10_ResNet18_ENN_epochs_20.keras\u001b[39m\u001b[38;5;124m'\u001b[39m, custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mENNLayer\u001b[39m\u001b[38;5;124m'\u001b[39m: ENNLayer})  \u001b[38;5;66;03m# Replace with actual path\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03mMP_classifier = tf.keras.models.load_model('W:/DS/Project/CNN Experiment/ResNet18/CIFAR10/CIFAR10_ResNet18_MP_epochs_20.keras')  # Replace with actual path\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03mRBF_classifier = tf.keras.models.load_model('W:/DS/Project/CNN Experiment/ResNet18/CIFAR10/CIFAR10_ResNet18_RBF_epochs_20.keras', custom_objects={'RBFLayer': RBFLayer})  # Replace with actual path\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03mECF_classifier = tf.keras.models.load_model('W:/DS/Project/CNN Experiment/ResNet18/CIFAR10/CIFAR10_ResNet18_ENN_epochs_20.keras', custom_objects={'ENNLayer': ENNLayer})  # Replace with actual path\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:182\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    179\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir:\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    183\u001b[0m         filepath,\n\u001b[0;32m    184\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    186\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    187\u001b[0m     )\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[0;32m    190\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m    191\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:237\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m     )\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_model_from_fileobj(\n\u001b[0;32m    238\u001b[0m         f, custom_objects, \u001b[38;5;28mcompile\u001b[39m, safe_mode\n\u001b[0;32m    239\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:314\u001b[0m, in \u001b[0;36m_load_model_from_fileobj\u001b[1;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zf\u001b[38;5;241m.\u001b[39mopen(_CONFIG_FILENAME, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    312\u001b[0m     config_json \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m--> 314\u001b[0m model \u001b[38;5;241m=\u001b[39m _model_from_config(\n\u001b[0;32m    315\u001b[0m     config_json, custom_objects, \u001b[38;5;28mcompile\u001b[39m, safe_mode\n\u001b[0;32m    316\u001b[0m )\n\u001b[0;32m    318\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[0;32m    319\u001b[0m weights_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:303\u001b[0m, in \u001b[0;36m_model_from_config\u001b[1;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[1;32m--> 303\u001b[0m     model \u001b[38;5;241m=\u001b[39m deserialize_keras_object(\n\u001b[0;32m    304\u001b[0m         config_dict, custom_objects, safe_mode\u001b[38;5;241m=\u001b[39msafe_mode\n\u001b[0;32m    305\u001b[0m     )\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:720\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    718\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(inner_config)\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    721\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m could not be deserialized properly. Please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ensure that components that are Python object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    723\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m instances (layers, models, etc.) returned by\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    724\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `get_config()` are explicitly deserialized in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    725\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms `from_config()` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    726\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    727\u001b[0m     )\n\u001b[0;32m    728\u001b[0m build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m build_config \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m instance\u001b[38;5;241m.\u001b[39mbuilt:\n",
      "\u001b[1;31mTypeError\u001b[0m: <class 'keras.src.models.functional.Functional'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras.src.models.functional', 'class_name': 'Functional', 'config': {'name': 'functional', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': [None, 512], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer'}, 'registered_name': None, 'name': 'input_layer', 'inbound_nodes': []}, {'module': 'custom_RBF_neuron', 'class_name': 'RBFLayer', 'config': {'name': 'rbf_layer', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 100, 'gamma': {'class_name': '__tensor__', 'config': {'value': 602.0853881835938, 'dtype': 'float32'}}}, 'registered_name': 'RBFLayer', 'build_config': {'input_shape': [None, 512]}, 'name': 'rbf_layer', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 512], 'dtype': 'float32', 'keras_history': ['input_layer', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 2681578012624}, 'units': 10, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 100]}, 'name': 'dense', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 100], 'dtype': 'float32', 'keras_history': ['rbf_layer', 0, 0]}}], 'kwargs': {}}]}], 'input_layers': [['input_layer', 0, 0]], 'output_layers': [['dense', 0, 0]]}, 'registered_name': 'Functional', 'build_config': {'input_shape': None}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'adam', 'learning_rate': 0.00019999999494757503, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': {'module': 'keras.losses', 'class_name': 'CategoricalCrossentropy', 'config': {'name': 'categorical_crossentropy', 'reduction': 'sum_over_batch_size', 'from_logits': False, 'label_smoothing': 0.0, 'axis': -1}, 'registered_name': None}, 'loss_weights': None, 'metrics': [{'module': 'keras.metrics', 'class_name': 'CategoricalAccuracy', 'config': {'name': 'categorical_accuracy', 'dtype': 'float32'}, 'registered_name': None}, {'module': 'keras.metrics', 'class_name': 'Precision', 'config': {'name': 'precision', 'dtype': 'float32', 'thresholds': None, 'top_k': None, 'class_id': None}, 'registered_name': None}, {'module': 'keras.metrics', 'class_name': 'Recall', 'config': {'name': 'recall', 'dtype': 'float32', 'thresholds': None, 'top_k': None, 'class_id': None}, 'registered_name': None}, {'module': 'keras.metrics', 'class_name': 'F1Score', 'config': {'name': 'f1_score', 'dtype': 'float32', 'average': 'micro', 'threshold': None}, 'registered_name': None}], 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': False}}.\n\nException encountered: <class 'custom_RBF_neuron.RBFLayer'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'custom_RBF_neuron', 'class_name': 'RBFLayer', 'config': {'name': 'rbf_layer', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 100, 'gamma': {'class_name': '__tensor__', 'config': {'value': 602.0853881835938, 'dtype': 'float32'}}}, 'registered_name': 'RBFLayer', 'build_config': {'input_shape': [None, 512]}, 'name': 'rbf_layer', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 512], 'dtype': 'float32', 'keras_history': ['input_layer', 0, 0]}}], 'kwargs': {}}]}.\n\nException encountered: Error when deserializing class 'RBFLayer' using config={'name': 'rbf_layer', 'trainable': True, 'dtype': 'float32', 'units': 100, 'gamma': {'class_name': '__tensor__', 'config': {'value': 602.0853881835938, 'dtype': 'float32'}}}.\n\nException encountered: Unrecognized keyword arguments passed to RBFLayer: {'gamma': {'class_name': '__tensor__', 'config': {'value': 602.0853881835938, 'dtype': 'float32'}}}"
     ]
    }
   ],
   "source": [
    "# Load TensorFlow classifier\n",
    "neurons = ['MP','RBF','ECF']\n",
    "MP_classifier = tf.keras.models.load_model('E:/Work/DS/Project/CNN Experiment/ResNet18/CIFAR10/CIFAR10_ResNet18_MP_epochs_20.keras')  # Replace with actual path\n",
    "RBF_classifier = tf.keras.models.load_model('E:/Work/DS/Project/CNN Experiment/ResNet18/CIFAR10/CIFAR10_ResNet18_RBF_epochs_20.keras', custom_objects={'RBFLayer': RBFLayer})  # Replace with actual path\n",
    "ECF_classifier = tf.keras.models.load_model('E:/Work/DS/Project/CNN Experiment/ResNet18/CIFAR10/CIFAR10_ResNet18_ENN_epochs_20.keras', custom_objects={'ENNLayer': ENNLayer})  # Replace with actual path\n",
    "\n",
    "'''\n",
    "MP_classifier = tf.keras.models.load_model('W:/DS/Project/CNN Experiment/ResNet18/CIFAR10/CIFAR10_ResNet18_MP_epochs_20.keras')  # Replace with actual path\n",
    "RBF_classifier = tf.keras.models.load_model('W:/DS/Project/CNN Experiment/ResNet18/CIFAR10/CIFAR10_ResNet18_RBF_epochs_20.keras', custom_objects={'RBFLayer': RBFLayer})  # Replace with actual path\n",
    "ECF_classifier = tf.keras.models.load_model('W:/DS/Project/CNN Experiment/ResNet18/CIFAR10/CIFAR10_ResNet18_ENN_epochs_20.keras', custom_objects={'ENNLayer': ENNLayer})  # Replace with actual path\n",
    "'''\n",
    "\n",
    "classifiers = [MP_classifier,RBF_classifier,ECF_classifier]\n",
    "\n",
    "# setup attacks\n",
    "attack_types_name = ['FGM', 'IFGM', 'FSGM', 'IFGSM', 'L-BFGS', 'Deepfool']\n",
    "# Run evaluation\n",
    "evaluate_adversarial(epsilon=0.007, classifiers = classifiers, classifiers_names = neurons, attacks_names = attack_types_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(221)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "extract_feature = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_feature:\n",
    "    import timm\n",
    "\n",
    "    model = timm.create_model(\n",
    "        'resnet18.a1_in1k',\n",
    "        pretrained=True,\n",
    "        num_classes=0,  # remove classifier nn.Linear\n",
    "    )\n",
    "    model = model.eval()\n",
    "\n",
    "    # get model specific transforms (normalization, resize)\n",
    "    data_config = timm.data.resolve_model_data_config(model)\n",
    "    transforms = timm.data.create_transform(**data_config, is_training=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test print image from Cifar 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_feature:\n",
    "    test = unpickle('E:/Work/DS/Datasets/Raw/cifar-10-batches-py/train/data_batch_1')\n",
    "\n",
    "    img = test[b'data'][0].reshape((3,32,32)).transpose(1,2,0).astype(\"uint8\") # frog???\n",
    "    label = test[b'filenames'][0]\n",
    "    plt.imshow(img)\n",
    "    plt.title(label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "if extract_feature:\n",
    "    # Directory containing subdirectories for each class\n",
    "    base_dir = 'E:/Work/DS/Datasets/Raw/cifar-10-batches-py/train'\n",
    "\n",
    "    cifar10 = []\n",
    "\n",
    "    # Iterate through each subdirectory\n",
    "    for batch_file_name in os.listdir(base_dir):\n",
    "        file_dir = os.path.join(base_dir, batch_file_name)\n",
    "        cifar10.append(unpickle(file_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process images from the cifar10 for the unwrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_minibatch(minibatch):\n",
    "    batch_data = []\n",
    "    for image in minibatch:\n",
    "        # Convert to PIL image format\n",
    "        img = Image.fromarray(image.reshape(3,32,32).transpose(1,2,0))\n",
    "        # transform to model format and stack\n",
    "        img = transforms(img)\n",
    "        batch_data.append(img)\n",
    "    batch_data = torch.stack(batch_data)\n",
    "    # run through the resnet\n",
    "    processed_data = model(batch_data)\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(file):\n",
    "\n",
    "    output_df = pd.DataFrame(columns=['Class'])\n",
    "\n",
    "    MINIBATCH_SIZE = 200\n",
    "\n",
    "\n",
    "    for k,batch in enumerate(file):\n",
    "        print('processing batch', k+1)\n",
    "        # get images\n",
    "        images = batch[b'data']\n",
    "        labels = batch[b'labels']\n",
    "        # Convert the list of images to a batch tensor\n",
    "        for i in range(0,int(10000/MINIBATCH_SIZE)):\n",
    "            print('processing minibatch %d out of %d' %(i+1 , int(10000/MINIBATCH_SIZE)))\n",
    "            minibatch = images[i*MINIBATCH_SIZE:(i+1)*MINIBATCH_SIZE]\n",
    "\n",
    "            # get features and put into df format\n",
    "            minibatch_output = process_minibatch(minibatch)\n",
    "            minibatch_output_df = pd.DataFrame(minibatch_output.detach().numpy(), columns=[f'features_{i}' for i in range(512)])\n",
    "            minibatch_output_df['Class'] = labels[i*MINIBATCH_SIZE:(i+1)*MINIBATCH_SIZE]\n",
    "\n",
    "            output_df = pd.concat([output_df, minibatch_output_df], ignore_index=True)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_feature:\n",
    "    output_df = feature_extraction(cifar10)\n",
    "    output_df.to_csv('extracted_features_train.csv', index = False)\n",
    "else:\n",
    "    output_df = pd.read_csv('extracted_features_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Class  features_0  features_1  features_2  features_3  features_4  \\\n",
      "0      6    0.040742    0.035822    0.222851    0.015412    0.486823   \n",
      "1      9    0.672252    0.000000    0.342131    0.000000    0.073739   \n",
      "2      9    0.301723    0.000000    0.134019    0.081969    0.069278   \n",
      "3      4    0.000000    0.000000    0.128621    0.001375    0.219229   \n",
      "4      1    0.142378    0.000000    0.067117    0.044040    0.281984   \n",
      "\n",
      "   features_5  features_6  features_7  features_8  ...  features_502  \\\n",
      "0    0.015395    0.189043    0.500762    0.499615  ...      0.109454   \n",
      "1    0.000000    0.123008    0.251687    0.029337  ...      0.135525   \n",
      "2    0.001227    0.045751    0.047892    0.386089  ...      0.219279   \n",
      "3    0.063678    0.005415    0.165327    0.888420  ...      0.119232   \n",
      "4    0.221451    0.032381    0.138317    0.583788  ...      0.000000   \n",
      "\n",
      "   features_503  features_504  features_505  features_506  features_507  \\\n",
      "0      0.391888      0.035869      0.041942      0.680499      0.617150   \n",
      "1      1.281373      0.405868      0.000000      0.058778      0.074560   \n",
      "2      0.207228      0.072956      0.002798      0.102566      0.043786   \n",
      "3      0.244319      0.048261      0.030268      0.302496      0.018989   \n",
      "4      0.603535      0.303451      0.000000      0.038988      0.058191   \n",
      "\n",
      "   features_508  features_509  features_510  features_511  \n",
      "0      0.306534      0.007564      0.148896      0.012736  \n",
      "1      0.063702      1.132170      0.026337      0.000000  \n",
      "2      0.204728      0.508546      0.370723      0.291213  \n",
      "3      0.047324      0.234554      0.118996      0.113055  \n",
      "4      0.000000      0.796191      0.000000      0.107168  \n",
      "\n",
      "[5 rows x 513 columns]\n",
      "(50000, 513)\n"
     ]
    }
   ],
   "source": [
    "print(output_df.head())\n",
    "print(output_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_feature:\n",
    "    cifar10_test = [unpickle('test_batch')]\n",
    "    test = feature_extraction(cifar10_test)\n",
    "    test.to_csv('extracted_features_test.csv', index = False)\n",
    "else:\n",
    "    test = pd.read_csv('extracted_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X_train = output_df.drop(columns = 'Class')\n",
    "y_train = output_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features_0</th>\n",
       "      <th>features_1</th>\n",
       "      <th>features_2</th>\n",
       "      <th>features_3</th>\n",
       "      <th>features_4</th>\n",
       "      <th>features_5</th>\n",
       "      <th>features_6</th>\n",
       "      <th>features_7</th>\n",
       "      <th>features_8</th>\n",
       "      <th>features_9</th>\n",
       "      <th>...</th>\n",
       "      <th>features_502</th>\n",
       "      <th>features_503</th>\n",
       "      <th>features_504</th>\n",
       "      <th>features_505</th>\n",
       "      <th>features_506</th>\n",
       "      <th>features_507</th>\n",
       "      <th>features_508</th>\n",
       "      <th>features_509</th>\n",
       "      <th>features_510</th>\n",
       "      <th>features_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040742</td>\n",
       "      <td>0.035822</td>\n",
       "      <td>0.222851</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.486823</td>\n",
       "      <td>0.015395</td>\n",
       "      <td>0.189043</td>\n",
       "      <td>0.500762</td>\n",
       "      <td>0.499615</td>\n",
       "      <td>0.259726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109454</td>\n",
       "      <td>0.391888</td>\n",
       "      <td>0.035869</td>\n",
       "      <td>0.041942</td>\n",
       "      <td>0.680499</td>\n",
       "      <td>0.617150</td>\n",
       "      <td>0.306534</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.148896</td>\n",
       "      <td>0.012736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.672252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123008</td>\n",
       "      <td>0.251687</td>\n",
       "      <td>0.029337</td>\n",
       "      <td>0.153819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135525</td>\n",
       "      <td>1.281373</td>\n",
       "      <td>0.405868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058778</td>\n",
       "      <td>0.074560</td>\n",
       "      <td>0.063702</td>\n",
       "      <td>1.132170</td>\n",
       "      <td>0.026337</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.301723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134019</td>\n",
       "      <td>0.081969</td>\n",
       "      <td>0.069278</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.045751</td>\n",
       "      <td>0.047892</td>\n",
       "      <td>0.386089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219279</td>\n",
       "      <td>0.207228</td>\n",
       "      <td>0.072956</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.102566</td>\n",
       "      <td>0.043786</td>\n",
       "      <td>0.204728</td>\n",
       "      <td>0.508546</td>\n",
       "      <td>0.370723</td>\n",
       "      <td>0.291213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128621</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.219229</td>\n",
       "      <td>0.063678</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.165327</td>\n",
       "      <td>0.888420</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119232</td>\n",
       "      <td>0.244319</td>\n",
       "      <td>0.048261</td>\n",
       "      <td>0.030268</td>\n",
       "      <td>0.302496</td>\n",
       "      <td>0.018989</td>\n",
       "      <td>0.047324</td>\n",
       "      <td>0.234554</td>\n",
       "      <td>0.118996</td>\n",
       "      <td>0.113055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.142378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067117</td>\n",
       "      <td>0.044040</td>\n",
       "      <td>0.281984</td>\n",
       "      <td>0.221451</td>\n",
       "      <td>0.032381</td>\n",
       "      <td>0.138317</td>\n",
       "      <td>0.583788</td>\n",
       "      <td>0.302565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603535</td>\n",
       "      <td>0.303451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038988</td>\n",
       "      <td>0.058191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.796191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.035197</td>\n",
       "      <td>0.058702</td>\n",
       "      <td>0.095312</td>\n",
       "      <td>0.037450</td>\n",
       "      <td>0.053576</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.259931</td>\n",
       "      <td>0.056354</td>\n",
       "      <td>0.170153</td>\n",
       "      <td>0.235934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091722</td>\n",
       "      <td>0.405168</td>\n",
       "      <td>0.130961</td>\n",
       "      <td>0.093053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213820</td>\n",
       "      <td>0.491387</td>\n",
       "      <td>0.074986</td>\n",
       "      <td>0.036422</td>\n",
       "      <td>0.115289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.273047</td>\n",
       "      <td>0.074760</td>\n",
       "      <td>0.267747</td>\n",
       "      <td>0.831988</td>\n",
       "      <td>0.431168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513849</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>0.031651</td>\n",
       "      <td>0.264359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578580</td>\n",
       "      <td>0.111145</td>\n",
       "      <td>0.319857</td>\n",
       "      <td>0.160226</td>\n",
       "      <td>0.279058</td>\n",
       "      <td>0.053023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139410</td>\n",
       "      <td>0.300243</td>\n",
       "      <td>0.138246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025550</td>\n",
       "      <td>0.014554</td>\n",
       "      <td>0.588634</td>\n",
       "      <td>0.062992</td>\n",
       "      <td>0.616284</td>\n",
       "      <td>0.037790</td>\n",
       "      <td>0.070613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098866</td>\n",
       "      <td>0.067091</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019947</td>\n",
       "      <td>0.597903</td>\n",
       "      <td>0.878241</td>\n",
       "      <td>0.015466</td>\n",
       "      <td>0.088653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.037763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136463</td>\n",
       "      <td>0.370930</td>\n",
       "      <td>0.484324</td>\n",
       "      <td>0.004421</td>\n",
       "      <td>0.222002</td>\n",
       "      <td>0.478854</td>\n",
       "      <td>0.056549</td>\n",
       "      <td>0.032293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194435</td>\n",
       "      <td>0.268003</td>\n",
       "      <td>0.049738</td>\n",
       "      <td>0.033890</td>\n",
       "      <td>0.275827</td>\n",
       "      <td>0.030199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235028</td>\n",
       "      <td>0.012788</td>\n",
       "      <td>0.300287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.023211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.159833</td>\n",
       "      <td>0.620174</td>\n",
       "      <td>0.016002</td>\n",
       "      <td>0.034277</td>\n",
       "      <td>0.158599</td>\n",
       "      <td>0.309702</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158672</td>\n",
       "      <td>0.374362</td>\n",
       "      <td>0.029272</td>\n",
       "      <td>0.097099</td>\n",
       "      <td>0.212243</td>\n",
       "      <td>0.047205</td>\n",
       "      <td>0.058019</td>\n",
       "      <td>0.053052</td>\n",
       "      <td>0.056359</td>\n",
       "      <td>0.052717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   features_0  features_1  features_2  features_3  features_4  features_5  \\\n",
       "0    0.040742    0.035822    0.222851    0.015412    0.486823    0.015395   \n",
       "1    0.672252    0.000000    0.342131    0.000000    0.073739    0.000000   \n",
       "2    0.301723    0.000000    0.134019    0.081969    0.069278    0.001227   \n",
       "3    0.000000    0.000000    0.128621    0.001375    0.219229    0.063678   \n",
       "4    0.142378    0.000000    0.067117    0.044040    0.281984    0.221451   \n",
       "5    1.035197    0.058702    0.095312    0.037450    0.053576    0.013230   \n",
       "6    0.273047    0.074760    0.267747    0.831988    0.431168    0.000000   \n",
       "7    0.001875    0.000000    0.025550    0.014554    0.588634    0.062992   \n",
       "8    0.037763    0.000000    0.136463    0.370930    0.484324    0.004421   \n",
       "9    0.023211    0.000000    0.229256    0.159833    0.620174    0.016002   \n",
       "\n",
       "   features_6  features_7  features_8  features_9  ...  features_502  \\\n",
       "0    0.189043    0.500762    0.499615    0.259726  ...      0.109454   \n",
       "1    0.123008    0.251687    0.029337    0.153819  ...      0.135525   \n",
       "2    0.045751    0.047892    0.386089    0.000000  ...      0.219279   \n",
       "3    0.005415    0.165327    0.888420    0.382979  ...      0.119232   \n",
       "4    0.032381    0.138317    0.583788    0.302565  ...      0.000000   \n",
       "5    0.259931    0.056354    0.170153    0.235934  ...      0.091722   \n",
       "6    0.513849    0.082853    0.031651    0.264359  ...      0.578580   \n",
       "7    0.616284    0.037790    0.070613    0.000000  ...      0.098866   \n",
       "8    0.222002    0.478854    0.056549    0.032293  ...      0.194435   \n",
       "9    0.034277    0.158599    0.309702    0.085020  ...      0.158672   \n",
       "\n",
       "   features_503  features_504  features_505  features_506  features_507  \\\n",
       "0      0.391888      0.035869      0.041942      0.680499      0.617150   \n",
       "1      1.281373      0.405868      0.000000      0.058778      0.074560   \n",
       "2      0.207228      0.072956      0.002798      0.102566      0.043786   \n",
       "3      0.244319      0.048261      0.030268      0.302496      0.018989   \n",
       "4      0.603535      0.303451      0.000000      0.038988      0.058191   \n",
       "5      0.405168      0.130961      0.093053      0.000000      0.213820   \n",
       "6      0.111145      0.319857      0.160226      0.279058      0.053023   \n",
       "7      0.067091      0.008325      0.000000      0.000000      0.019947   \n",
       "8      0.268003      0.049738      0.033890      0.275827      0.030199   \n",
       "9      0.374362      0.029272      0.097099      0.212243      0.047205   \n",
       "\n",
       "   features_508  features_509  features_510  features_511  \n",
       "0      0.306534      0.007564      0.148896      0.012736  \n",
       "1      0.063702      1.132170      0.026337      0.000000  \n",
       "2      0.204728      0.508546      0.370723      0.291213  \n",
       "3      0.047324      0.234554      0.118996      0.113055  \n",
       "4      0.000000      0.796191      0.000000      0.107168  \n",
       "5      0.491387      0.074986      0.036422      0.115289  \n",
       "6      0.000000      0.139410      0.300243      0.138246  \n",
       "7      0.597903      0.878241      0.015466      0.088653  \n",
       "8      0.000000      0.235028      0.012788      0.300287  \n",
       "9      0.058019      0.053052      0.056359      0.052717  \n",
       "\n",
       "[10 rows x 512 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X_train.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
